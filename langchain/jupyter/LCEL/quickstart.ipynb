{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b42dcc-c644-45a6-8a6a-3b250c74cee7",
   "metadata": {},
   "source": [
    "## Langchain Expression Languageï¼ˆLCELï¼‰å¿«é€Ÿå…¥é—¨\n",
    "\n",
    "LCEL æ˜¯ LangChain ä¸­çš„ä¸€ä¸ªé‡è¦æ¦‚å¿µï¼Œ**LCELæ˜¯ä¸€ç§å£°æ˜å¼çš„é“¾å¼ç»„åˆè¯­è¨€**ã€‚å®ƒæä¾›äº†ä¸€ç§ç»Ÿä¸€çš„æ¥å£ï¼Œå…è®¸ä¸åŒçš„ç»„ä»¶ï¼ˆå¦‚ `retriever`, `prompt`, `llm` ç­‰ï¼‰å¯ä»¥é€šè¿‡ç»Ÿä¸€çš„ `Runnable` æ¥å£è¿æ¥èµ·æ¥ã€‚æ¯ä¸ª `Runnable` ç»„ä»¶éƒ½å®ç°äº†ç›¸åŒçš„æ–¹æ³•ï¼Œå¦‚ `.invoke()`ã€`.stream()` æˆ– `.batch()`ï¼Œè¿™ä½¿å¾—å®ƒä»¬å¯ä»¥é€šè¿‡ `|` æ“ä½œç¬¦è½»æ¾è¿æ¥ã€‚\n",
    "\n",
    "### LCEL çš„ä¼˜åŠ¿\n",
    "\n",
    "LCELä½¿å¾—ä»åŸºæœ¬ç»„ä»¶æ„å»ºå¤æ‚é“¾å˜å¾—å®¹æ˜“ï¼Œå¹¶æ”¯æŒæµå¼å¤„ç†ã€å¹¶è¡Œå¤„ç†å’Œæ—¥å¿—è®°å½•ç­‰å¼€ç®±å³ç”¨çš„åŠŸèƒ½ã€‚\n",
    "\n",
    "- **ç»Ÿä¸€æ¥å£**: LCEL é€šè¿‡ `Runnable` æ¥å£å°†ä¸åŒçš„ç»„ä»¶ç»Ÿä¸€èµ·æ¥ï¼Œç®€åŒ–äº†å¤æ‚æ“ä½œçš„å®ç°ã€‚\n",
    "- **æ¨¡å—åŒ–**: å„ä¸ªç»„ä»¶å¯ä»¥ç‹¬ç«‹å¼€å‘å’Œæµ‹è¯•ï¼Œç„¶åé€šè¿‡ LCEL è½»æ¾é›†æˆã€‚\n",
    "- **å¯æ‰©å±•æ€§**: LCEL æ”¯æŒå¼‚æ­¥è°ƒç”¨ã€æ‰¹å¤„ç†å’Œæµå¼å¤„ç†ï¼Œé€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯ã€‚\n",
    "\n",
    "\n",
    "### ç»„ä»¶\n",
    "\n",
    "æˆ‘ä»¬å·²å­¦ä¹ çš„ç»„ä»¶åŒ…æ‹¬ä»¥ä¸‹æ¨¡å—ï¼š\n",
    "\n",
    "#### ğŸ“ƒ Model I/Oï¼š\n",
    "\n",
    "è¿™åŒ…æ‹¬æç¤ºç®¡ç†ï¼Œæç¤ºä¼˜åŒ–ï¼Œç”¨äºèŠå¤©æ¨¡å‹å’ŒLLMçš„é€šç”¨æ¥å£ï¼Œä»¥åŠå¤„ç†æ¨¡å‹è¾“å‡ºçš„å¸¸è§å®ç”¨å·¥å…·ã€‚\n",
    "\n",
    "#### ğŸ“š Retrievalï¼š\n",
    "\n",
    "æ£€ç´¢å¢å¼ºç”Ÿæˆæ¶‰åŠä»å„ç§æ¥æºåŠ è½½æ•°æ®ï¼Œå‡†å¤‡æ•°æ®ï¼Œç„¶ååœ¨ç”Ÿæˆæ­¥éª¤ä¸­æ£€ç´¢æ•°æ®ä»¥ä¾›ä½¿ç”¨ã€‚\n",
    "\n",
    "#### ğŸ¤– Agentsï¼š\n",
    "\n",
    "Agents å…è®¸LLMè‡ªä¸»å®Œæˆä»»åŠ¡ã€‚ Agentsä¼šå†³å®šé‡‡å–å“ªäº›è¡ŒåŠ¨ï¼Œç„¶åæ‰§è¡Œè¯¥è¡ŒåŠ¨ï¼Œå¹¶è§‚å¯Ÿç»“æœï¼Œå¹¶é‡å¤æ­¤è¿‡ç¨‹ç›´åˆ°ä»»åŠ¡å®Œæˆã€‚ LangChainä¸ºä»£ç†æä¾›äº†æ ‡å‡†æ¥å£ã€å¯é€‰æ‹©çš„ä»£ç†åˆ—è¡¨ä»¥åŠç«¯åˆ°ç«¯ä»£ç†ç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b55489-48a5-4c2e-9a6e-3f246f0881c6",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ LCEL å®ç° LLMChainï¼ˆPrompt + LLM)\n",
    "\n",
    "#### Pipe ç®¡é“æ“ä½œç¬¦\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨LCELçš„ `|` æ“ä½œç¬¦å°†è¿™äº›ä¸åŒç»„ä»¶æ‹¼æ¥æˆä¸€ä¸ªå•ä¸€é“¾ã€‚\n",
    "\n",
    "**åœ¨è¿™ä¸ªé“¾ä¸­ï¼Œç”¨æˆ·è¾“å…¥è¢«ä¼ é€’åˆ°æç¤ºæ¨¡æ¿ï¼Œç„¶åæç¤ºæ¨¡æ¿çš„è¾“å‡ºè¢«ä¼ é€’åˆ°æ¨¡å‹ï¼Œæ¥ç€æ¨¡å‹çš„è¾“å‡ºè¢«ä¼ é€’åˆ°è¾“å‡ºè§£æå™¨ã€‚**\n",
    "\n",
    "```python\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "ç«–çº¿ç¬¦å·ç±»ä¼¼äºUnixç®¡é“æ“ä½œç¬¦ï¼Œå®ƒå°†ä¸åŒçš„ç»„ä»¶é“¾æ¥åœ¨ä¸€èµ·ï¼Œå°†ä¸€ä¸ªç»„ä»¶çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªç»„ä»¶çš„è¾“å…¥ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dca913e-3dc0-4d3c-9b4a-d2de9525aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# è¾“å…¥å¹¶è®¾ç½® OpenAI API å¯†é’¥\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-*****'\n",
    "os.environ[\"OPENAI_API_BASE\"] = 'https://dashscope.aliyuncs.com/compatible-mode/v1'\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = 'sk-*****'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09242ff5-b5ff-4902-9de8-59e4af945bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å½“ç„¶å¯ä»¥ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç¨‹åºå‘˜å¯èƒ½ä¼šä¼šå¿ƒä¸€ç¬‘çš„ç¬‘è¯ï¼š\\n\\nä¸ºä»€ä¹ˆç¨‹åºå‘˜ä¸å–œæ¬¢åœ¨æˆ·å¤–å·¥ä½œï¼Ÿ\\nå› ä¸ºé‚£é‡Œæœ‰å¤ªå¤šçš„ bugsï¼ˆè™«å­/é”™è¯¯ï¼‰ï¼\\n\\nè¿™ä¸ªç¬‘è¯å·§å¦™åœ°åˆ©ç”¨äº†â€œbugsâ€è¿™ä¸ªè¯çš„åŒå…³å«ä¹‰ï¼Œåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­æŒ‡çš„æ˜¯æ˜†è™«ï¼Œè€Œåœ¨ç¼–ç¨‹é¢†åŸŸä¸­åˆ™æŒ‡ä»£ç¨‹åºä¸­çš„é”™è¯¯æˆ–ç¼ºé™·ã€‚å¸Œæœ›è¿™èƒ½ç»™ä½ å¸¦æ¥ä¸€ä¸æ¬¢ä¹ï¼'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# åˆå§‹åŒ– ChatOpenAI æ¨¡å‹ï¼ŒæŒ‡å®šä½¿ç”¨çš„æ¨¡å‹ä¸º 'gpt-4o-mini'\n",
    "model = ChatOpenAI(model=\"qwen-max\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªèŠå¤©æç¤ºæ¨¡æ¿ï¼Œè®¾ç½®æ¨¡æ¿å†…å®¹ä¸º\"è®²ä¸ªå…³äº {topic} çš„ç¬‘è¯å§\"\n",
    "prompt = ChatPromptTemplate.from_template(\"è®²ä¸ªå…³äº {topic} çš„ç¬‘è¯å§\")\n",
    "\n",
    "# åˆå§‹åŒ–è¾“å‡ºè§£æå™¨ï¼Œç”¨äºå°†æ¨¡å‹çš„è¾“å‡ºè½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# æ„å»ºä¸€ä¸ªå¤„ç†é“¾ï¼Œå…ˆé€šè¿‡æç¤ºæ¨¡æ¿ç”Ÿæˆå®Œæ•´çš„è¾“å…¥ï¼Œç„¶åé€šè¿‡æ¨¡å‹å¤„ç†ï¼Œæœ€åè§£æè¾“å‡º\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# è°ƒç”¨å¤„ç†é“¾ï¼Œä¼ å…¥ä¸»é¢˜ä¸º\"ç¨‹åºå‘˜\"ï¼Œç”Ÿæˆå…³äºç¨‹åºå‘˜çš„ç¬‘è¯\n",
    "chain.invoke({\"topic\": \"ç¨‹åºå‘˜\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4cd1e-7d55-4b14-ae37-9f7d66b07892",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒæ¦‚å¿µï¼šinvoke æ–¹æ³•\n",
    "\n",
    "Langchain `invoke` æ–¹æ³•æ˜¯ LCEL è®¾è®¡ä¸­çš„é‡è¦æ–¹æ³•ï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…æ›´é«˜æ•ˆåœ°å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œç»“åˆè¯­è¨€æ¨¡å‹è¿›è¡Œç³»ç»Ÿæ„å»ºï¼Œå®ç°ä¸åŒæ•°æ®æºå’ŒAPIçš„æ¥å£å¯¹æ¥ã€‚\n",
    "\n",
    "### åŸºç¡€æ¦‚å¿µ\n",
    "\n",
    "- åœ¨Langchainä¸­ï¼Œinvokeæ–¹æ³•æ˜¯æ‰€æœ‰LangChainè¡¨è¾¾å¼è¯­è¨€ï¼ˆLCELï¼‰å¯¹è±¡çš„é€šç”¨åŒæ­¥è°ƒç”¨æ–¹æ³•ã€‚é€šè¿‡invokeæ–¹æ³•ï¼Œå¼€å‘è€…å¯ä»¥ç›´æ¥è°ƒç”¨LLMæˆ–ChatModelï¼Œç®€åŒ–äº†è°ƒç”¨æµç¨‹ï¼Œæé«˜äº†å¼€å‘æ•ˆç‡ã€‚\n",
    "- ä¸å…¶ä»–é“¾å¼è°ƒç”¨æ–¹æ³•ç›¸æ¯”ï¼Œinvokeæ–¹æ³•æ›´åŠ çµæ´»ä¾¿æ·ï¼Œå¯ä»¥ç›´æ¥å¯¹è¾“å…¥è¿›è¡Œè°ƒç”¨ï¼Œè€Œä¸éœ€è¦é¢å¤–çš„é“¾å¼æ“ä½œã€‚ç›¸å¯¹äºbatchå’Œstreamç­‰å¼‚æ­¥æ–¹æ³•ï¼Œinvokeæ–¹æ³•æ›´é€‚ç”¨äºå•ä¸€æ“ä½œçš„æ‰§è¡Œã€‚\n",
    "\n",
    "### ä½¿ç”¨æ–¹å¼\n",
    "\n",
    "- å•æ¬¡è°ƒç”¨ï¼šé€šè¿‡invokeæ–¹æ³•ï¼Œå¼€å‘è€…å¯ä»¥å¿«é€Ÿå¯¹å•ä¸€æ“ä½œè¿›è¡Œæ‰§è¡Œï¼Œä¾‹å¦‚è½¬æ¢ChatMessageä¸ºPythonå­—ç¬¦ä¸²ç­‰ç®€å•æ“ä½œï¼Œæå‡äº†ä»£ç çš„å¯è¯»æ€§å’Œæ•´æ´åº¦ã€‚\n",
    "- å¤æ‚åä½œï¼šLangchainçš„æ ¸å¿ƒç†å¿µå°±æ˜¯å°†è¯­è¨€æ¨¡å‹ä½œä¸ºåä½œå·¥å…·ï¼Œinvokeæ–¹æ³•å¯ä»¥å¾ˆå¥½åœ°å®ç°å¼€å‘è€…ä¸è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆäº’åŠ¨ï¼Œæ„å»ºå‡ºå¤„ç†å¤æ‚ä»»åŠ¡çš„ç³»ç»Ÿï¼Œå¹¶å¯¹æ¥ä¸åŒçš„æ•°æ®æºå’ŒAPIæ¥å£ã€‚\n",
    "\n",
    "## invoke ä¸ Model I/O çš„ç»“åˆ\n",
    "\n",
    "æ•´ä¸ªæµç¨‹æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š\n",
    "\n",
    "1. `Prompt` ç»„ä»¶æ¥æ”¶ç”¨æˆ·è¾“å…¥ **{\"topic\": \"ç¨‹åºå‘˜\"}**ï¼Œç„¶åä½¿ç”¨è¯¥ topic æ„å»º `PromptValue`\n",
    "1. `Model` ç»„ä»¶è·å–ç”Ÿæˆçš„æç¤ºï¼Œå¹¶ä¼ é€’ç»™ GPT-3.5-Turbo æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚ä»æ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºæ˜¯ä¸€ä¸ªChatMessageå¯¹è±¡ã€‚\n",
    "1. æœ€åï¼Œ`output_parser` ç»„ä»¶æ¥æ”¶ChatMessageï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºPythonå­—ç¬¦ä¸²ï¼Œåœ¨invokeæ–¹æ³•ä¸­è¿”å›ã€‚\n",
    "\n",
    "### Prompt\n",
    "\n",
    "`prompt` æ˜¯ `BasePromptTemplate` çš„å®ä¾‹ï¼Œè¿™æ„å‘³ç€å®ƒæ¥å—æ¨¡æ¿å˜é‡çš„å­—å…¸å¹¶ç”Ÿæˆä¸€ä¸ª`PromptValue`ã€‚ \n",
    "\n",
    "PromptValueæ˜¯ä¸€ä¸ªåŒ…è£…å™¨(wrapper)ï¼Œå›´ç»•å®Œæˆçš„æç¤ºè¿›è¡Œæ“ä½œï¼Œå¯ä»¥ä¼ é€’ç»™LLMï¼ˆä»¥å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥ï¼‰æˆ–ChatModelï¼ˆä»¥æ¶ˆæ¯åºåˆ—ä½œä¸ºè¾“å…¥ï¼‰ã€‚ \n",
    "\n",
    "å®ƒå¯ä»¥ä¸ä»»ä½•è¯­è¨€æ¨¡å‹ç±»å‹ä¸€èµ·ä½¿ç”¨ï¼Œå› ä¸ºå®ƒå®šä¹‰äº†ç”Ÿæˆ`BaseMessages`å’Œç”Ÿæˆå­—ç¬¦ä¸²çš„é€»è¾‘ã€‚\n",
    "\n",
    "```python\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Prompt é LCEL ä½¿ç”¨æ–¹æ³•\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"è®²ä¸ªå…³äº {topic} çš„ç¬‘è¯å§\"\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨ format ç”Ÿæˆæç¤º\n",
    "prompt = prompt_template.format(topic=\"ç¨‹åºå‘˜\")\n",
    "print(prompt)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4b0ead-76d5-43e1-ba40-590b20894c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='è®²ä¸ªå…³äº ç¨‹åºå‘˜ çš„ç¬‘è¯å§')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è°ƒç”¨ Prompt çš„ invoke æ–¹æ³•ç”Ÿæˆæœ€ç»ˆçš„æç¤ºè¯\n",
    "prompt_value = prompt.invoke({\"topic\": \"ç¨‹åºå‘˜\"})\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea46f7e-67cb-44c5-a5c1-6311a2a75639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='è®²ä¸ªå…³äº ç¨‹åºå‘˜ çš„ç¬‘è¯å§')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é€‚ç”¨äº ChatModel çš„ Message æ ¼å¼\n",
    "prompt_value.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6030b5-f19f-42ee-9405-0bc229bd3c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: è®²ä¸ªå…³äº ç¨‹åºå‘˜ çš„ç¬‘è¯å§'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å­—ç¬¦ä¸²æ ¼å¼\n",
    "prompt_value.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d7c57-fd05-44b2-9638-2923ff532e0e",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "ç„¶åè°ƒç”¨æ¨¡å‹çš„ `invoke` æ–¹æ³•ï¼Œå°† `PromptValue` ä¼ é€’ç»™æ¨¡å‹ã€‚\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨çš„ `GPT-4o-mini` æ¨¡å‹æ˜¯ ChatModelï¼Œinvoke æ–¹æ³•å°†è¿”å› BaseMessageã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c82e786d-52f1-4082-92b5-00f3029d5983",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = model.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6a7a85-c1da-4441-a1db-cab6d0bd32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='å½“ç„¶å¯ä»¥ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç¨‹åºå‘˜å¯èƒ½ä¼šä¼šå¿ƒä¸€ç¬‘çš„ç¬‘è¯ï¼š\\n\\nä¸ºä»€ä¹ˆç¨‹åºå‘˜ä¸å–œæ¬¢åœ¨æˆ·å¤–å·¥ä½œï¼Ÿ\\nå› ä¸ºé‚£é‡Œæœ‰å¤ªå¤šçš„ bugsï¼ˆè™«å­/é”™è¯¯ï¼‰ï¼ \\n\\nè¿™ä¸ªç¬‘è¯ç©å‘³äº†\"bugs\"è¿™ä¸ªè¯çš„åŒé‡å«ä¹‰ï¼Œåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å®ƒæŒ‡çš„æ˜¯æ˜†è™«ï¼Œè€Œåœ¨ç¼–ç¨‹é¢†åŸŸä¸­åˆ™æ˜¯æŒ‡ç¨‹åºä¸­çš„é”™è¯¯ã€‚å¸Œæœ›è¿™èƒ½è®©ä½ ç¬‘ä¸€ç¬‘ï¼', response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 19, 'total_tokens': 88, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-max', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-979b0087-7256-4d3f-a11b-b78a963f05fc-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e36bb7-c7b3-49f1-9e6e-3a04c2d39d46",
   "metadata": {},
   "source": [
    "å¦‚æœæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ LLM æ¨¡å‹  `gpt-3.5-turbo-instruct`ï¼Œinvoke æ–¹æ³•å°±ä¼šè¿”å›å­—ç¬¦ä¸²ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b56176b-65d6-41f4-8071-058593e47a2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': '', 'param': None, 'message': 'Invalid URL (POST /compatible-api/v1/completions)', 'type': 'invalid_request_error'}, 'request_id': '68f4b039-08b6-9b23-9ef4-6552c7c65df3'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.3-70b-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/langchain_openai/llms/base.py:350\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     choices\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    335\u001b[0m         {\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m         }\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 350\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/openai/resources/completions.py:539\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    538\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_of\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/OpenAiQuickStart2/lib/python3.10/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '', 'param': None, 'message': 'Invalid URL (POST /compatible-api/v1/completions)', 'type': 'invalid_request_error'}, 'request_id': '68f4b039-08b6-9b23-9ef4-6552c7c65df3'}"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"llama3.3-70b-instruct\")\n",
    "llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91e1e1-c670-4803-a7d6-6b05df266961",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "\n",
    "æœ€åï¼Œæˆ‘ä»¬å°†æ¨¡å‹è¾“å‡ºä¼ é€’ç»™ output_parserï¼Œå®ƒæ˜¯ä¸€ä¸ª `BaseOutputParser` ç¤ºä¾‹ï¼Œæ„å‘³ç€å®ƒæ¥å—å­—ç¬¦ä¸²æˆ– BaseMessage ä½œä¸ºè¾“å…¥ã€‚\n",
    "\n",
    "æœ¬æŒ‡å—ä¸­ä½¿ç”¨çš„ `StrOutputParser` ç¤ºä¾‹å°†æ‰€æœ‰è¾“å…¥éƒ½è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "150ceaf0-fcc1-4756-8fca-ab9bf28ed94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å½“ç„¶å¯ä»¥ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç¨‹åºå‘˜å¯èƒ½ä¼šä¼šå¿ƒä¸€ç¬‘çš„ç¬‘è¯ï¼š\\n\\nä¸ºä»€ä¹ˆç¨‹åºå‘˜ä¸å–œæ¬¢åœ¨æˆ·å¤–å·¥ä½œï¼Ÿ\\nå› ä¸ºé‚£é‡Œæœ‰å¤ªå¤šçš„ bugsï¼ˆè™«å­/é”™è¯¯ï¼‰ï¼ \\n\\nè¿™ä¸ªç¬‘è¯ç©å‘³äº†\"bugs\"è¿™ä¸ªè¯çš„åŒé‡å«ä¹‰ï¼Œåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å®ƒæŒ‡çš„æ˜¯æ˜†è™«ï¼Œè€Œåœ¨ç¼–ç¨‹é¢†åŸŸä¸­åˆ™æ˜¯æŒ‡ç¨‹åºä¸­çš„é”™è¯¯ã€‚å¸Œæœ›è¿™èƒ½è®©ä½ ç¬‘ä¸€ç¬‘ï¼'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# message ç»è¿‡ StrOutputParser å¤„ç†ï¼Œå˜ä¸ºæ ‡å‡†çš„å­—ç¬¦ä¸²\n",
    "output_parser.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e1741-83a4-4312-be93-76523e2c9373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02797bf-df69-4c7d-ba0a-35df38d53173",
   "metadata": {},
   "source": [
    "## Invoke ä¸ Retrieval ç»“åˆ\n",
    "\n",
    "ä¸‹é¢æ¼”ç¤ºå¦‚ä½•åœ¨ç»å…¸çš„ RAG åœºæ™¯ä¸­ä½¿ç”¨ invoke æ–¹æ³•ã€‚ä¸‹é¢å°†ä½¿ç”¨`|`æ“ä½œç¬¦å®ç°æ›´å¤æ‚çš„é“¾å¼è°ƒç”¨ã€‚\n",
    "\n",
    "```python\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "```\n",
    "ä¸ºäº†è§£é‡Šè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é¦–å…ˆå¯ä»¥çœ‹åˆ°ä¸Šé¢çš„æç¤ºæ¨¡æ¿æ¥å—ä¸Šä¸‹æ–‡å’Œé—®é¢˜ä½œä¸ºè¦æ›¿æ¢åœ¨æç¤ºä¸­çš„å€¼ã€‚åœ¨æ„å»ºæç¤ºæ¨¡æ¿ä¹‹å‰ï¼Œæˆ‘ä»¬å¸Œæœ›æ£€ç´¢ç›¸å…³æ–‡ä»¶ä»¥åŠå°†å®ƒä»¬åŒ…å«åœ¨ä¸Šä¸‹æ–‡ä¸­ã€‚\n",
    "\n",
    "ä½œä¸ºåˆæ­¥æ­¥éª¤ï¼Œæˆ‘ä»¬å·²ç»è®¾ç½®äº†ä½¿ç”¨å†…å­˜å­˜å‚¨å™¨çš„æ£€ç´¢å™¨ï¼Œå®ƒå¯ä»¥æ ¹æ®æŸ¥è¯¢æ£€ç´¢æ–‡æ¡£ã€‚è¿™ä¹Ÿæ˜¯ä¸€ä¸ªå¯è¿è¡Œçš„ç»„ä»¶ï¼Œå¹¶ä¸”å¯ä»¥ä¸å…¶ä»–ç»„ä»¶é“¾æ¥åœ¨ä¸€èµ·ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥å°è¯•å•ç‹¬è¿è¡Œå®ƒï¼š\n",
    "\n",
    "æ•´ä¸ªæµç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. é¦–å…ˆåˆ›å»ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªæ¡ç›®(entries)çš„ `RunnableParallel` å¯¹è±¡ **setup_and_retrieval**ã€‚ç¬¬ä¸€ä¸ªæ¡ç›®`context`å°†åŒ…æ‹¬æ£€ç´¢å™¨è·å–çš„æ–‡æ¡£ç»“æœã€‚ç¬¬äºŒä¸ªæ¡ç›®`question`å°†åŒ…å«ç”¨æˆ·åŸå§‹é—®é¢˜ã€‚ä¸ºäº†ä¼ é€’é—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨`RunnablePassthrough`æ¥å¤åˆ¶è¿™ä¸ªæ¡ç›®ã€‚\n",
    "2. å°†ä¸Šä¸€æ­¥ä¸­çš„å­—å…¸æä¾›ç»™`Prompt`ç»„ä»¶ã€‚ç„¶åï¼Œå®ƒæ¥æ”¶ç”¨æˆ·è¾“å…¥ï¼ˆå³é—®é¢˜ï¼‰ä»¥åŠæ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼ˆå³contextï¼‰ï¼Œæ„å»ºæç¤ºå¹¶è¾“å‡º`PromptValue`ã€‚\n",
    "3. `Model` ç»„ä»¶æ¥å—ç”Ÿæˆçš„æç¤ºï¼Œå¹¶ä¼ é€’ç»™OpenAI `gpt-4o-mini` æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚æ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºæ˜¯ä¸€ä¸ªChatMessageå¯¹è±¡ã€‚\n",
    "4. æœ€åï¼Œ`output_parser` ç»„ä»¶æ¥æ”¶ChatMessageï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºPythonå­—ç¬¦ä¸²ï¼Œåœ¨è°ƒç”¨æ–¹æ³•ä¸­è¿”å›è¯¥å­—ç¬¦ä¸²ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aa1a415-c38e-44c3-bda1-7e50aa6f7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"qwen-max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "188130e3-54d8-4efe-a40e-c0ab81f9e274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ï¼ŒHarrisonåœ¨Kenshoå·¥ä½œã€‚'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¼å…¥ LangChain åº“çš„ä¸åŒæ¨¡å—ï¼ŒåŒ…æ‹¬å‘é‡å­˜å‚¨ã€è¾“å‡ºè§£æå™¨ã€æç¤ºæ¨¡æ¿ã€å¹¶è¡Œè¿è¡Œå™¨å’Œ OpenAI çš„åµŒå…¥æ¨¡å‹\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "# ä½¿ç”¨ DocArrayInMemorySearch åˆ›å»ºä¸€ä¸ªå†…å­˜ä¸­çš„å‘é‡å­˜å‚¨\n",
    "# ä½¿ç”¨ OpenAIEmbeddings ä¸ºæ–‡æœ¬ç”ŸæˆåµŒå…¥å‘é‡ï¼Œæ–‡æœ¬ä¸º \"harrison worked at kensho\" å’Œ \"bears like to eat honey\"\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=DashScopeEmbeddings(),\n",
    ")\n",
    "\n",
    "# å°†å‘é‡å­˜å‚¨è½¬æ¢ä¸ºæ£€ç´¢å™¨\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªèŠå¤©æç¤ºæ¨¡æ¿ï¼Œç”¨ä¸­æ–‡è®¾ç½®æ¨¡æ¿ä»¥ä¾¿ç”ŸæˆåŸºäºç‰¹å®šä¸Šä¸‹æ–‡å’Œé—®é¢˜çš„å®Œæ•´è¾“å…¥\n",
    "template = \"\"\"æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜:\n",
    "{context}\n",
    "\n",
    "é—®é¢˜: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# åˆå§‹åŒ–è¾“å‡ºè§£æå™¨ï¼Œå°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# è®¾ç½®ä¸€ä¸ªå¹¶è¡Œè¿è¡Œå™¨ï¼Œç”¨äºåŒæ—¶å¤„ç†ä¸Šä¸‹æ–‡æ£€ç´¢å’Œé—®é¢˜ä¼ é€’\n",
    "# ä½¿ç”¨RunnableParallelæ¥å‡†å¤‡é¢„æœŸçš„è¾“å…¥ï¼Œé€šè¿‡ä½¿ç”¨æ£€ç´¢åˆ°çš„æ–‡æ¡£æ¡ç›®ä»¥åŠåŸå§‹ç”¨æˆ·é—®é¢˜ï¼Œ\n",
    "# åˆ©ç”¨æ–‡æ¡£æœç´¢å™¨ retriever è¿›è¡Œæ–‡æ¡£æœç´¢ï¼Œå¹¶ä½¿ç”¨ RunnablePassthrough æ¥ä¼ é€’ç”¨æˆ·çš„é—®é¢˜ã€‚\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "# æ„å»ºä¸€ä¸ªå¤„ç†é“¾ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡å’Œé—®é¢˜çš„è®¾ç½®ã€æç¤ºç”Ÿæˆã€æ¨¡å‹è°ƒç”¨å’Œè¾“å‡ºè§£æ\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "# è°ƒç”¨å¤„ç†é“¾ï¼Œä¼ å…¥é—®é¢˜\"where did harrison work?\"ï¼ˆéœ€ç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰ï¼Œå¹¶åŸºäºç»™å®šçš„æ–‡æœ¬ä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ\n",
    "chain.invoke(\"harrisonåœ¨å“ªé‡Œå·¥ä½œï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bcecfd-e726-4570-bea6-19cd5b8fbd15",
   "metadata": {},
   "source": [
    "#### å¿½ç•¥è­¦å‘Šæç¤ºï¼š\n",
    "\n",
    "UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
    "\n",
    "åŸå› ï¼š`The issue is with pydantic version, it's 2.0.0+ and not compatible with docarray.\n",
    "Instead it should be pydantic==1.10.9`\n",
    "\n",
    "å‚è€ƒï¼šhttps://github.com/langchain-ai/langchain/issues/15394\n",
    "\n",
    "LangChainå®˜æ–¹å…³äº Pydatic å…¼å®¹æ€§çš„è¯´æ˜ï¼šhttps://python.langchain.com/v0.1/docs/guides/development/pydantic_compatibility/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7027c6-d85a-4af7-b5ef-1949d88f082f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "800ffa20-782d-4f83-85e7-4349f8121186",
   "metadata": {},
   "source": [
    "### Homework: ä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨çš„å‘é‡æ•°æ®åº“æ›¿æ¢ DocArrayInMemorySearchï¼Œé‡å†™ LCEL ç‰ˆæœ¬çš„ RAG ç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82210b4c-df52-4b7f-abf2-97211ba9a7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7421b57-a9bf-40e6-9290-e12eb6210cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
